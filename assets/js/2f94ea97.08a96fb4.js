"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[786],{1209:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"Vla/conversational-ai","title":"Chapter 2: Conversational AI for Robotics","description":"2.1 Principles of Conversational AI","source":"@site/docs/06-Vla/02-conversational-ai.md","sourceDirName":"06-Vla","slug":"/Vla/conversational-ai","permalink":"/Physical-AI-Book/Vla/conversational-ai","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Voice-to-Action Systems","permalink":"/Physical-AI-Book/Vla/voice-to-action"},"next":{"title":"Chapter 3: Cognitive Planning for VLA","permalink":"/Physical-AI-Book/Vla/cognitive-planning"}}');var o=i(4848),a=i(8453);const r={},s="Chapter 2: Conversational AI for Robotics",l={},c=[{value:"2.1 Principles of Conversational AI",id:"21-principles-of-conversational-ai",level:2},{value:"2.1.1 Dialogue Management",id:"211-dialogue-management",level:3},{value:"2.1.1.1 State Tracking",id:"2111-state-tracking",level:4},{value:"2.1.1.1.1 Response Generation",id:"21111-response-generation",level:5},{value:"2.2 Integration with Robotic Systems",id:"22-integration-with-robotic-systems",level:2},{value:"2.2.1 Grounding Language in Perception",id:"221-grounding-language-in-perception",level:3},{value:"2.2.1.1 Action Confirmation and Clarification",id:"2211-action-confirmation-and-clarification",level:4}];function d(n){const e={h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",p:"p",...(0,a.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"chapter-2-conversational-ai-for-robotics",children:"Chapter 2: Conversational AI for Robotics"})}),"\n",(0,o.jsx)(e.h2,{id:"21-principles-of-conversational-ai",children:"2.1 Principles of Conversational AI"}),"\n",(0,o.jsx)(e.p,{children:"Conversational AI enables robots to engage in natural, human-like dialogue, understanding context, managing turns, and responding coherently to user queries and commands."}),"\n",(0,o.jsx)(e.h3,{id:"211-dialogue-management",children:"2.1.1 Dialogue Management"}),"\n",(0,o.jsx)(e.p,{children:"Dialogue management systems track the state of the conversation, resolve ambiguities, and decide on the robot's next action or response based on user input and internal goals."}),"\n",(0,o.jsx)(e.h4,{id:"2111-state-tracking",children:"2.1.1.1 State Tracking"}),"\n",(0,o.jsx)(e.p,{children:"Dialogue state tracking maintains a representation of the conversation's progress, including user intents, filled slots, and common ground established during the interaction."}),"\n",(0,o.jsx)(e.h5,{id:"21111-response-generation",children:"2.1.1.1.1 Response Generation"}),"\n",(0,o.jsx)(e.p,{children:"Response generation creates natural language outputs for the robot, which can be template-based, retrieval-based, or fully generative using large language models (LLMs)."}),"\n",(0,o.jsx)(e.h2,{id:"22-integration-with-robotic-systems",children:"2.2 Integration with Robotic Systems"}),"\n",(0,o.jsx)(e.p,{children:"Bringing conversational AI to robots involves integrating language understanding and generation with the robot's perception, planning, and action systems."}),"\n",(0,o.jsx)(e.h3,{id:"221-grounding-language-in-perception",children:"2.2.1 Grounding Language in Perception"}),"\n",(0,o.jsx)(e.p,{children:'For a robot to understand commands like "pick up the red block," the language must be grounded in its perception of the environment, linking linguistic entities to real-world objects.'}),"\n",(0,o.jsx)(e.h4,{id:"2211-action-confirmation-and-clarification",children:"2.2.1.1 Action Confirmation and Clarification"}),"\n",(0,o.jsx)(e.p,{children:"Robots can use conversational AI to confirm understanding of a command before execution or to ask clarifying questions when faced with ambiguous instructions."})]})}function u(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>s});var t=i(6540);const o={},a=t.createContext(o);function r(n){const e=t.useContext(a);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:r(n.components),t.createElement(a.Provider,{value:e},n.children)}}}]);