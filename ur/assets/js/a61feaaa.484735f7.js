"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[891],{8453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>s});var a=i(6540);const t={},o=a.createContext(t);function r(n){const e=a.useContext(o);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:r(n.components),a.createElement(o.Provider,{value:e},n.children)}},8733:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>c,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"Humanoid/interaction","title":"Chapter 5: Human-Robot Interaction (HRI)","description":"5.1 Principles of Human-Robot Interaction","source":"@site/docs/05-Humanoid/05-interaction.md","sourceDirName":"05-Humanoid","slug":"/Humanoid/interaction","permalink":"/Physical-AI-Book/ur/Humanoid/interaction","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Humanoid Robot Manipulation","permalink":"/Physical-AI-Book/ur/Humanoid/manipulation"},"next":{"title":"Chapter 1: Voice-to-Action Systems","permalink":"/Physical-AI-Book/ur/Vla/voice-to-action"}}');var t=i(4848),o=i(8453);const r={},s="Chapter 5: Human-Robot Interaction (HRI)",c={},l=[{value:"5.1 Principles of Human-Robot Interaction",id:"51-principles-of-human-robot-interaction",level:2},{value:"5.1.1 Safety and Trust",id:"511-safety-and-trust",level:3},{value:"5.1.1.1 Shared Autonomy",id:"5111-shared-autonomy",level:4},{value:"5.1.1.1.1 Transparency and Explainability",id:"51111-transparency-and-explainability",level:5},{value:"5.1.1.1.1.1 Ethical Considerations",id:"511111-ethical-considerations",level:6},{value:"5.2 Interaction Modalities",id:"52-interaction-modalities",level:2},{value:"5.2.1 Speech and Natural Language Processing (NLP)",id:"521-speech-and-natural-language-processing-nlp",level:3},{value:"5.2.1.1 Gesture Recognition",id:"5211-gesture-recognition",level:4},{value:"5.2.1.1.1 Haptic Feedback",id:"52111-haptic-feedback",level:5},{value:"5.2.1.1.1.1 Social Robotics",id:"521111-social-robotics",level:6}];function d(n){const e={h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",h6:"h6",header:"header",p:"p",...(0,o.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"chapter-5-human-robot-interaction-hri",children:"Chapter 5: Human-Robot Interaction (HRI)"})}),"\n",(0,t.jsx)(e.h2,{id:"51-principles-of-human-robot-interaction",children:"5.1 Principles of Human-Robot Interaction"}),"\n",(0,t.jsx)(e.p,{children:"Human-Robot Interaction (HRI) is a field dedicated to understanding, designing, and evaluating robotic systems for use by or with humans. Effective HRI is crucial for deploying humanoids in real-world scenarios."}),"\n",(0,t.jsx)(e.h3,{id:"511-safety-and-trust",children:"5.1.1 Safety and Trust"}),"\n",(0,t.jsx)(e.p,{children:"Ensuring the physical safety of humans interacting with robots is paramount. Building trust through predictable behavior, clear communication, and error recovery mechanisms is also vital."}),"\n",(0,t.jsx)(e.h4,{id:"5111-shared-autonomy",children:"5.1.1.1 Shared Autonomy"}),"\n",(0,t.jsx)(e.p,{children:"Shared autonomy approaches allow both humans and robots to contribute to task execution, balancing robot independence with human guidance and intervention when needed."}),"\n",(0,t.jsx)(e.h5,{id:"51111-transparency-and-explainability",children:"5.1.1.1.1 Transparency and Explainability"}),"\n",(0,t.jsx)(e.p,{children:"Transparent robots whose actions and intentions are easily understandable by humans, along with explainable AI (XAI) for their decision-making processes, enhance trust and collaboration."}),"\n",(0,t.jsx)(e.h6,{id:"511111-ethical-considerations",children:"5.1.1.1.1.1 Ethical Considerations"}),"\n",(0,t.jsx)(e.p,{children:"As humanoids become more capable, ethical considerations regarding their impact on society, employment, privacy, and accountability become increasingly important."}),"\n",(0,t.jsx)(e.h2,{id:"52-interaction-modalities",children:"5.2 Interaction Modalities"}),"\n",(0,t.jsx)(e.p,{children:"Humanoids can interact with humans through various modalities, including speech, gestures, touch, and visual cues, enabling natural and intuitive communication."}),"\n",(0,t.jsx)(e.h3,{id:"521-speech-and-natural-language-processing-nlp",children:"5.2.1 Speech and Natural Language Processing (NLP)"}),"\n",(0,t.jsx)(e.p,{children:"Speech recognition and natural language understanding allow humanoids to comprehend spoken commands and respond verbally, facilitating direct communication."}),"\n",(0,t.jsx)(e.h4,{id:"5211-gesture-recognition",children:"5.2.1.1 Gesture Recognition"}),"\n",(0,t.jsx)(e.p,{children:"Humanoid robots can interpret human gestures (e.g., pointing, waving) to understand intentions and context, enabling non-verbal communication and collaboration."}),"\n",(0,t.jsx)(e.h5,{id:"52111-haptic-feedback",children:"5.2.1.1.1 Haptic Feedback"}),"\n",(0,t.jsx)(e.p,{children:"Haptic feedback (e.g., vibrations, force feedback) can be used by robots to communicate information to humans or to provide a sense of touch during physical interaction."}),"\n",(0,t.jsx)(e.h6,{id:"521111-social-robotics",children:"5.2.1.1.1.1 Social Robotics"}),"\n",(0,t.jsx)(e.p,{children:"Social robotics focuses on developing robots that can interact with humans in a socially acceptable manner, understanding and expressing emotions, and engaging in social cues."})]})}function u(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}}}]);